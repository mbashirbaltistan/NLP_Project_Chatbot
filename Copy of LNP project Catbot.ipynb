{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7703,"status":"ok","timestamp":1694267494726,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"},"user_tz":420},"id":"ts4LuPhbjh7m","outputId":"cd16e2d0-b5f0-4ecc-f89b-a471187ce52d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"HZWElMNvjYR4","executionInfo":{"status":"ok","timestamp":1694267512961,"user_tz":420,"elapsed":570,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"}}},"outputs":[],"source":["import numpy as np\n","import time\n","import os\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rTfXFjXhnaks","executionInfo":{"status":"ok","timestamp":1694267514605,"user_tz":420,"elapsed":4,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"}}},"outputs":[],"source":["f = open('/content/intents.json', 'r', errors='ignore')\n","raw_doc = f.read()\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"2uVCZWQAojyH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694267534785,"user_tz":420,"elapsed":625,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"}},"outputId":"75c15f46-23fa-4ee0-9a5d-e441a45f9642"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\"intents\": [\n","  {\n","    \"tag\": \"hello\",\n","    \"patterns\": [ \"Hello\", \"Hi there\", \"Good morning\",  \"What's up\"   ],\n","    \"responses\": [  \"Hey!\",  \"Hello\", \"Hi!\", \"Good morning!\"    ],\n","    \"context\": \"\"\n","  },\n","  { \"tag\": \"noanswer\",\n","    \"patterns\": [],\n","    \"responses\": [\"Sorry, can't understand you\", \"Please give me more info\", \"Not sure I understand\" ],\n","    \"context\": [\"\"]\n","  },\n","        \n","  {\n","    \"tag\": \"job\",\n","    \"patterns\": [\"What is your job\", \"What is your work\"],\n","    \"responses\": [\"My job is to make you feel like everything is okay.\",\n","      \"I work to serve you as well as possible\"],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"age\",\n","    \"patterns\": [\"What is your age\",  \"How old are you\",  \"When were you born\"],\n","    \"responses\": [\"I was born in 2021\" ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"feeling\",\n","    \"patterns\": [\"How are you today\", \"How are you\"],\n","    \"responses\": [\"I am feeling good, you?\", \"Very good and you?\",  \"Actually, I'm okay and you?\"   ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"good\",\n","    \"patterns\": [\"I am good too\", \"I feel fine\", \"Good !\", \"Fine\", \"I am good\", \"I am great\", \"great\" ],\n","    \"responses\": [ \"That is perfect!\",\n","      \"So, everything's okay!\" ],\n","    \"context\": \"feeling\"\n","  },\n","  {\n","    \"tag\": \"bad\",\n","    \"patterns\": [ \"I am feeling bad\",  \"No I am sad\", \"No\"  ],\n","    \"responses\": [  \"I hope you will feel better !\"    ],\n","    \"context\": \"feeling\"\n","  },\n","  {\n","    \"tag\": \"actions\",\n","    \"patterns\": [  \"What can you do\",\n","      \"What can I ask you\",  \"Can you help me\" ],\n","    \"responses\": [ \"I can do a lot of things but here are some of my skills, you can ask me: the capital of a country, its currency and its area. A random number. To calculate a math operation.\" ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"women\",\n","    \"patterns\": [  \"Are you a girl\", \"You are a women\" ],\n","    \"responses\": [ \"Sure, I am a women\" ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"men\",\n","    \"patterns\": [ \"Are you a men\",  \"Are you a boy\" ],\n","    \"responses\": [\"No, I am a women\" ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"thanks\",\n","    \"patterns\": [ \"Thank you\",   \"Thank you very much\",  \"thanks\"  ],\n","    \"responses\": [  \"I only do my jobï¸\", \"No problem!\"  ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"goodbye\",\n","    \"patterns\": [   \"Goodbye\",  \"Good afternoon\",   \"Bye\"   ],\n","    \"responses\": [  \"Goodbye!\",  \"See you soon!\" ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"city\",\n","    \"patterns\": [  \"Where do you live\" ],\n","    \"responses\": [  \"I live in a server located in the US!\"\n","    ],\n","    \"context\": \"\"  },\n","  {\n","    \"tag\": \"action\",\n","    \"patterns\": [  \"What are you doing\"\n","    ],\n","    \"responses\": [  \"Actually, I'm chatting with somebody\" ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"wait\",\n","    \"patterns\": [ \"Can you wait 2 minutes\",  \"Please wait\", \"Wait 2 secs please\" ],\n","    \"responses\": [ \"Sure! I wait.\"  ],\n","    \"context\": \"\"\n","  },\n","  {\n","    \"tag\": \"still there\",\n","    \"patterns\": [  \"Are you still there?\", \"Are you here?\"   ],\n","    \"responses\": [ \"Of course! Always at your service.\" ],\n","    \"context\": \"\"\n","  }\n","   ]\n","}\n"]}],"source":["print (raw_doc)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"cKD0p5K_jfIQ","executionInfo":{"status":"ok","timestamp":1694267553716,"user_tz":420,"elapsed":6659,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"}}},"outputs":[],"source":["# checkpoint\n","checkpoint = \"microsoft/DialoGPT-medium\"\n","# download and cache tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","# download and cache pre-trained model\n","model = AutoModelForCausalLM.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"u0RznmD2l6lI","executionInfo":{"status":"ok","timestamp":1694267557552,"user_tz":420,"elapsed":644,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"}}},"outputs":[],"source":["# Build a ChatBot class with all necessary modules to make a complete conversation\n","class ChatBot():\n","    # initialize\n","    def __init__(self):\n","        # once chat starts, the history will be stored for chat continuity\n","        self.chat_history_ids = None\n","        # make input ids global to use them anywhere within the object\n","        self.bot_input_ids = None\n","        # a flag to check whether to end the conversation\n","        self.end_chat = False\n","        # greet while starting\n","        self.welcome()\n","\n","    def welcome(self):\n","        print(\"Initializing ChatBot ...\")\n","        # some time to get user ready\n","        time.sleep(2)\n","        print('Type \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n","        # give time to read what has been printed\n","        time.sleep(3)\n","        # Greet and introduce\n","        greeting = np.random.choice([\n","            \"Welcome, I am ChatBot, here for your kind service\",\n","            \"Hey, Great day! I am your virtual assistant\",\n","            \"Hello, it's my pleasure meeting you\",\n","            \"Hi, I am a ChatBot. Let's chat!\"\n","        ])\n","        print(\"ChatBot >>  \" + greeting)\n","\n","    def user_input(self):\n","        # receive input from user\n","        text = input(\"User    >> \")\n","        # end conversation if user wishes so\n","        if text.lower().strip() in ['bye', 'quit', 'exit']:\n","            # turn flag on\n","            self.end_chat=True\n","            # a closing comment\n","            print('ChatBot >>  See you soon! Bye!')\n","            time.sleep(1)\n","            print('\\nQuitting ChatBot ...')\n","        else:\n","            # continue chat, preprocess input text\n","            # encode the new user input, add the eos_token and return a tensor in Pytorch\n","            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, \\\n","                                                       return_tensors='pt')\n","\n","    def bot_response(self):\n","        # append the new user input tokens to the chat history\n","        # if chat has already begun\n","        if self.chat_history_ids is not None:\n","            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1)\n","        else:\n","            # if first entry, initialize bot_input_ids\n","            self.bot_input_ids = self.new_user_input_ids\n","\n","        # define the new chat_history_ids based on the preceding chats\n","        # generated a response while limiting the total chat history to 1000 tokens,\n","        self.chat_history_ids = model.generate(self.bot_input_ids, max_length=1000, \\\n","                                               pad_token_id=tokenizer.eos_token_id)\n","\n","        # last ouput tokens from bot\n","        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n","                               skip_special_tokens=True)\n","        # in case, bot fails to answer\n","        if response == \"\":\n","            response = self.random_response()\n","        # print bot response\n","        print('ChatBot >>  '+ response)\n","\n","    # in case there is no response from model\n","    def random_response(self):\n","        i = -1\n","        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n","                               skip_special_tokens=True)\n","        # iterate over history backwards to find the last token\n","        while response == '':\n","            i = i-1\n","            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n","                               skip_special_tokens=True)\n","        # if it is a question, answer suitably\n","        if response.strip() == '?':\n","            reply = np.random.choice([\"I don't know\",\n","                                     \"I am not sure\"])\n","        # not a question? answer suitably\n","        else:\n","            reply = np.random.choice([\"Great\",\n","                                      \"Fine. What's up?\",\n","                                      \"Okay\"\n","                                     ])\n","        return reply"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"7ySoGEL-mGSP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694267697602,"user_tz":420,"elapsed":83455,"user":{"displayName":"M. Bashir Baltistani","userId":"14982930470889588226"}},"outputId":"2f790a8c-8d1b-430f-aa60-660e8f7ebaa6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing ChatBot ...\n","Type \"bye\" or \"quit\" or \"exit\" to end chat \n","\n","ChatBot >>  Welcome, I am ChatBot, here for your kind service\n","User    >> hello\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["ChatBot >>  Hello! :D\n","User    >> how are you\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["ChatBot >>  I'm good, how are you?\n","User    >> i am also good\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["ChatBot >>  I'm good too\n","User    >> thaks for reply\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["ChatBot >>  You're welcome\n","User    >> okey bye\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["ChatBot >>  bye bye\n","User    >> exit\n","ChatBot >>  See you soon! Bye!\n","\n","Quitting ChatBot ...\n"]}],"source":["# build a ChatBot object\n","bot = ChatBot()\n","# start chatting\n","while True:\n","    # receive user input\n","    bot.user_input()\n","    # check whether to end chat\n","    if bot.end_chat:\n","        break\n","    # output bot response\n","    bot.bot_response()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1aYp9T7GoEhby1iS8Y9X7zaciwuxxAXUx","timestamp":1694267759563}],"authorship_tag":"ABX9TyOctP4pgn6g0EetwOZu+PX5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}